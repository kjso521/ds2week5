{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SBS 평가: Denoising (학습 모델) + Deconvolution (최소제곱법)\n",
        "\n",
        "이 노트북은 Step-by-Step 파이프라인의 중간 성능을 확인하기 위해 제작되었습니다.\n",
        "- **1단계 (Denoising)**: 학습된 DnCNN 모델을 사용하여 노이즈를 제거합니다.\n",
        "- **2단계 (Deconvolution)**: 고전적인 이미지 복원 기법인 최소제곱법(Least Squares)을 사용하여 Deconvolution을 수행합니다.\n",
        "\n",
        "이를 통해 전체 SBS 파이프라인(DnCNN + Unet)의 학습이 완료되기 전에 Denoising 모델의 성능과 한계를 잠정적으로 평가할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 1. 환경 설정\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 프로젝트 폴더 경로 설정 (본인의 환경에 맞게 수정)\n",
        "import os\n",
        "PROJECT_PATH = \"/content/drive/MyDrive/Data Scientist/Project/Week5/week5\"\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "# 시스템 경로에 프로젝트 루트 추가\n",
        "import sys\n",
        "sys.path.append(PROJECT_PATH)\n",
        "\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title (Optional) 1-1. Install Dependencies\n",
        "# @markdown `loguru` 라이브러리가 설치되어 있지 않은 경우에만 이 셀을 실행하세요.\n",
        "%pip install loguru --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 2. 설정값 정의\n",
        "# @markdown ---\n",
        "# @markdown ### **1. 필수 경로 설정**\n",
        "# @markdown Denoising 모델의 체크포인트 파일 경로를 지정하세요.\n",
        "DENOISING_CKPT_PATH = \"logs_sbs_denoising_dncnn/00001_train/checkpoints/checkpoint_best.ckpt\" # @param {type:\"string\"}\n",
        "# @markdown ---\n",
        "# @markdown ### **2. 데이터 및 결과 폴더 설정**\n",
        "# @markdown 테스트 데이터셋과 결과 파일을 저장할 폴더를 지정하세요.\n",
        "TEST_DATA_PATH = \"dataset/test_y\" # @param {type:\"string\"}\n",
        "RESULT_DIR = \"result_sbs_denoising_ls_joint\" # @param {type:\"string\"}\n",
        "# @markdown ---\n",
        "# @markdown ### **3. 공동 복원 하이퍼파라미터**\n",
        "# @markdown Regularization 강도 (0에 가까울수록 강한 복원, 클수록 노이즈 억제)\n",
        "LAMBDA = 1e-3 # @param {type:\"number\"}\n",
        "# @markdown ---\n",
        "\n",
        "print(f\"✅ Joint Deconvolution (All Angles) Mode Enabled.\")\n",
        "print(f\"Denoising Checkpoint: {DENOISING_CKPT_PATH}\")\n",
        "print(f\"Test Data: {TEST_DATA_PATH}\")\n",
        "print(f\"Result Directory: {RESULT_DIR} (Joint)\")\n",
        "print(f\"Deconvolution Lambda: {LAMBDA}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 3. 다각도 공동 복원(Joint Deconvolution) 함수 구현\n",
        "import torch\n",
        "import torch.fft as fft\n",
        "from dataset.forward_simulator import ForwardSimulator, dipole_kernel\n",
        "from params import config as global_config\n",
        "\n",
        "# 디바이스 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 모든 방향에 대한 Dipole Kernel을 k-space 상에서 미리 생성\n",
        "dipole_kernels_k = [\n",
        "    dipole_kernel(matrix_size=global_config.image_size, B0_dir=direction).to(device)\n",
        "    for direction in global_config.conv_directions\n",
        "]\n",
        "print(f\"✅ Successfully created {len(dipole_kernels_k)} dipole kernels for joint deconvolution.\")\n",
        "\n",
        "\n",
        "def joint_deconv_all_angles(denoised_tensor: torch.Tensor, kernels_k: list[torch.Tensor], lambda_reg: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Performs joint deconvolution using all available angles (directions).\n",
        "    Implements the formula: X_hat = sum(H_conj * Y) / (sum(|H|^2) + lambda)\n",
        "    \"\"\"\n",
        "    # 입력 이미지를 k-space로 변환\n",
        "    denoised_k = fft.fftn(denoised_tensor, dim=(-2, -1))\n",
        "\n",
        "    # 분자(numerator)와 분모(denominator)의 합을 저장할 텐서 초기화\n",
        "    # torch.zeros_like()를 사용하여 동일한 shape과 device를 갖도록 함\n",
        "    numerator_sum = torch.zeros_like(denoised_k)\n",
        "    denominator_sum = torch.zeros_like(torch.abs(kernels_k[0])**2)\n",
        "    \n",
        "    # 각 각도(theta)에 대해 분자/분모를 누적\n",
        "    for kernel_k in kernels_k:\n",
        "        numerator_sum += torch.conj(kernel_k) * denoised_k\n",
        "        denominator_sum += torch.abs(kernel_k)**2\n",
        "        \n",
        "    # 최종 수식 적용\n",
        "    denominator_sum += lambda_reg\n",
        "    \n",
        "    # 0으로 나누는 것을 방지\n",
        "    denominator_sum[denominator_sum == 0] = 1.0\n",
        "    \n",
        "    deconv_k = numerator_sum / denominator_sum\n",
        "    \n",
        "    # 다시 이미지 공간으로 변환\n",
        "    deconv_image = fft.ifftn(deconv_k, dim=(-2, -1))\n",
        "    \n",
        "    # 실수부만 반환\n",
        "    return deconv_image.real\n",
        "\n",
        "print(\"Joint deconvolution function is ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 4. Denoising 모델 로드\n",
        "from pathlib import Path\n",
        "from code_denoising.core_funcs import get_model, ModelType\n",
        "from params import dncnnconfig\n",
        "\n",
        "print(f\"Loading Denoising checkpoint from: {DENOISING_CKPT_PATH}\")\n",
        "\n",
        "try:\n",
        "    denoising_ckpt_path = Path(DENOISING_CKPT_PATH)\n",
        "    if not denoising_ckpt_path.exists():\n",
        "        raise FileNotFoundError(f\"Denoising checkpoint not found at {denoising_ckpt_path}\")\n",
        "\n",
        "    denoising_checkpoint = torch.load(denoising_ckpt_path, map_location=device)\n",
        "    \n",
        "    # 모델 타입 및 설정 할당\n",
        "    global_config.model_type = denoising_checkpoint.get(\"model_type\", \"dncnn\")\n",
        "    global_config.model_config = dncnnconfig\n",
        "    \n",
        "    # 모델 생성 및 state_dict 로드\n",
        "    denoising_network = get_model(global_config).to(device)\n",
        "    denoising_network.load_state_dict(denoising_checkpoint['model_state_dict'])\n",
        "    denoising_network.eval()\n",
        "    \n",
        "    print(f\"Successfully loaded Denoising model ({global_config.model_type}).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the model: {e}\")\n",
        "    denoising_network = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 5. 파이프라인 실행 및 결과 저장\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from code_denoising.datawrapper.datawrapper import DataKey, get_data_wrapper_loader, LoaderConfig\n",
        "\n",
        "if denoising_network:\n",
        "    # --- 기존 결과 폴더 삭제 ---\n",
        "    result_path = Path(RESULT_DIR)\n",
        "    if result_path.exists():\n",
        "        print(f\"Removing old '{RESULT_DIR}' directory...\")\n",
        "        shutil.rmtree(result_path)\n",
        "    result_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # --- 데이터 로더 설정 ---\n",
        "    loader_cfg: LoaderConfig = {\n",
        "        \"data_type\": global_config.data_type,\n",
        "        \"batch\": 8, # GPU 메모리에 맞춰 배치 크기 조절 가능\n",
        "        \"num_workers\": 2,\n",
        "        \"shuffle\": False,\n",
        "        \"augmentation_mode\": 'none',\n",
        "        \"training_phase\": 'end_to_end',\n",
        "        \"noise_type\": global_config.noise_type,\n",
        "        \"noise_levels\": global_config.noise_levels,\n",
        "        \"conv_directions\": global_config.conv_directions\n",
        "    }\n",
        "    data_loader, _ = get_data_wrapper_loader(\n",
        "        file_path=[TEST_DATA_PATH],\n",
        "        training_mode=False,\n",
        "        data_wrapper_class='controlled',\n",
        "        **loader_cfg\n",
        "    )\n",
        "\n",
        "    if not data_loader:\n",
        "        print(f\"Failed to create data loader from {TEST_DATA_PATH}. No data found?\")\n",
        "    else:\n",
        "        print(f\"\\n[Phase 1/1] Creating result files from Denoising + Joint Deconvolution pipeline...\")\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(data_loader, desc=\"Processing images\"):\n",
        "                image_noise = data[DataKey.image_noise].to(device)\n",
        "                filenames = data[DataKey.name]\n",
        "\n",
        "                # Step 1: Denoising (학습 모델)\n",
        "                denoised_image_batch = denoising_network(image_noise)\n",
        "\n",
        "                # Step 2: Joint Deconvolution (다각도 공동 복원)\n",
        "                # 배치 내 각 이미지에 대해 개별적으로 복원 수행\n",
        "                for i in range(denoised_image_batch.shape[0]):\n",
        "                    single_denoised_tensor = denoised_image_batch[i:i+1]\n",
        "                    \n",
        "                    # 새로 구현된 공동 복원 함수 호출\n",
        "                    final_image_tensor = joint_deconv_all_angles(\n",
        "                        single_denoised_tensor, \n",
        "                        dipole_kernels_k, \n",
        "                        LAMBDA\n",
        "                    )\n",
        "\n",
        "                    # 결과 저장\n",
        "                    pred_np = final_image_tensor.squeeze().cpu().numpy()\n",
        "                    base_filename = Path(filenames[i]).stem\n",
        "                    np.save(result_path / f\"{base_filename}.npy\", pred_np)\n",
        "        \n",
        "        print(f\"\\nFinished! Results are saved in '{RESULT_DIR}'.\")\n",
        "        print(\"You can now run the 'evaluate.ipynb' notebook to calculate the scores.\")\n",
        "else:\n",
        "    print(\"\\nSkipping pipeline execution because the model failed to load.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
