{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SBS 평가: Denoising (학습 모델) + Deconvolution (최소제곱법)\n",
        "\n",
        "이 노트북은 Step-by-Step 파이프라인의 중간 성능을 확인하기 위해 제작되었습니다.\n",
        "- **1단계 (Denoising)**: 학습된 DnCNN 모델을 사용하여 노이즈를 제거합니다.\n",
        "- **2단계 (Deconvolution)**: 고전적인 이미지 복원 기법인 최소제곱법(Least Squares)을 사용하여 Deconvolution을 수행합니다.\n",
        "\n",
        "이를 통해 전체 SBS 파이프라인(DnCNN + Unet)의 학습이 완료되기 전에 Denoising 모델의 성능과 한계를 잠정적으로 평가할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 1. 환경 설정\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 프로젝트 폴더 경로 설정 (본인의 환경에 맞게 수정)\n",
        "import os\n",
        "PROJECT_PATH = \"/content/drive/MyDrive/Data Scientist/Project/Week5/week5\"\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "# 시스템 경로에 프로젝트 루트 추가\n",
        "import sys\n",
        "sys.path.append(PROJECT_PATH)\n",
        "\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 2. 설정값 정의\n",
        "# @markdown ---\n",
        "# @markdown ### **1. 실행 모드 선택**\n",
        "# @markdown - **Robust**: 5개 방향을 모두 테스트하여 이미지별 최적 결과를 자동으로 찾습니다. (권장)\n",
        "# @markdown - **Manual**: 아래에 지정된 단일 방향으로만 모든 이미지를 복원합니다. (실험용)\n",
        "EVALUATION_MODE = \"Robust (All Directions)\" # @param [\"Robust (All Directions)\", \"Manual (Single Direction)\"]\n",
        "# @markdown ---\n",
        "# @markdown ### **2. 필수 경로 설정**\n",
        "# @markdown Denoising 모델의 체크포인트 파일 경로를 지정하세요.\n",
        "DENOISING_CKPT_PATH = \"logs_sbs_denoising_dncnn/00001_train/checkpoints/checkpoint_best.ckpt\" # @param {type:\"string\"}\n",
        "# @markdown ---\n",
        "# @markdown ### **3. 데이터 및 결과 폴더 설정**\n",
        "# @markdown 테스트 데이터셋과 결과 파일을 저장할 폴더를 지정하세요.\n",
        "TEST_DATA_PATH = \"dataset/test_y\" # @param {type:\"string\"}\n",
        "RESULT_DIR = \"result_sbs_denoising_ls\" # @param {type:\"string\"}\n",
        "# @markdown ---\n",
        "# @markdown ### **4. 최소제곱법 하이퍼파라미터**\n",
        "# @markdown Regularization 강도 (0에 가까울수록 강한 복원, 클수록 노이즈 억제)\n",
        "LAMBDA = 1e-3 # @param {type:\"number\"}\n",
        "# @markdown ---\n",
        "# @markdown ### **5. (Manual 모드 전용) B0 방향 수동 설정**\n",
        "# @markdown `EVALUATION_MODE`가 `Manual`일 때만 사용됩니다.\n",
        "B0_DIR_X = 0.309 # @param {type:\"number\"}\n",
        "B0_DIR_Y = -0.9511 # @param {type:\"number\"}\n",
        "MANUAL_B0_DIRECTION = (B0_DIR_X, B0_DIR_Y)\n",
        "# @markdown ---\n",
        "print(f\"✅ Evaluation Mode: {EVALUATION_MODE}\")\n",
        "print(f\"Denoising Checkpoint: {DENOISING_CKPT_PATH}\")\n",
        "print(f\"Test Data: {TEST_DATA_PATH}\")\n",
        "print(f\"Result Directory: {RESULT_DIR}\")\n",
        "print(f\"Least Squares Lambda: {LAMBDA}\")\n",
        "if EVALUATION_MODE == 'Manual (Single Direction)':\n",
        "    print(f\"Manual B0 Direction: {MANUAL_B0_DIRECTION}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 3. 최소제곱법(Least Squares) 복원 함수 구현\n",
        "import torch\n",
        "import torch.fft as fft\n",
        "from dataset.forward_simulator import ForwardSimulator\n",
        "from params import config as global_config, conv_directions\n",
        "\n",
        "# 디바이스 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ForwardSimulator를 한 번만 초기화\n",
        "H, W = global_config.image_size\n",
        "forward_simulator = ForwardSimulator(image_dims=(H, W))\n",
        "\n",
        "# 💡 수정: 선택된 EVALUATION_MODE에 따라 커널을 생성\n",
        "if EVALUATION_MODE == \"Robust (All Directions)\":\n",
        "    dipole_kernels_k = [\n",
        "        forward_simulator._create_dipole_kernel(B0_direction=direction).to(device)\n",
        "        for direction in conv_directions\n",
        "    ]\n",
        "    print(f\"✅ Robust Mode: Successfully created {len(dipole_kernels_k)} dipole kernels.\")\n",
        "else: # Manual (Single Direction)\n",
        "    dipole_kernels_k = [\n",
        "        forward_simulator._create_dipole_kernel(B0_direction=MANUAL_B0_DIRECTION).to(device)\n",
        "    ]\n",
        "    print(f\"✅ Manual Mode: Successfully created 1 dipole kernel for direction {MANUAL_B0_DIRECTION}.\")\n",
        "\n",
        "\n",
        "def least_squares_deconv(denoised_tensor: torch.Tensor, kernel_k: torch.Tensor, lambda_reg: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Performs Least Squares deconvolution in the Fourier domain.\n",
        "    \"\"\"\n",
        "    # 입력 이미지를 k-space로 변환\n",
        "    denoised_k = fft.fftn(denoised_tensor, dim=(-2, -1))\n",
        "    \n",
        "    # 최소제곱법 공식 적용\n",
        "    kernel_k_conj = torch.conj(kernel_k)\n",
        "    kernel_mag_sq = torch.abs(kernel_k)**2\n",
        "    \n",
        "    numerator = kernel_k_conj * denoised_k\n",
        "    denominator = kernel_mag_sq + lambda_reg\n",
        "    \n",
        "    # 0으로 나누는 것을 방지\n",
        "    denominator[denominator == 0] = 1.0\n",
        "    \n",
        "    deconv_k = numerator / denominator\n",
        "    \n",
        "    # 다시 이미지 공간으로 변환\n",
        "    deconv_image = fft.ifftn(deconv_k, dim=(-2, -1))\n",
        "    \n",
        "    # 실수부만 반환\n",
        "    return deconv_image.real\n",
        "\n",
        "print(\"Least Squares deconvolution function is ready.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 4. Denoising 모델 로드\n",
        "from pathlib import Path\n",
        "from code_denoising.core_funcs import get_model, ModelType\n",
        "from params import dncnnconfig\n",
        "\n",
        "print(f\"Loading Denoising checkpoint from: {DENOISING_CKPT_PATH}\")\n",
        "\n",
        "try:\n",
        "    denoising_ckpt_path = Path(DENOISING_CKPT_PATH)\n",
        "    if not denoising_ckpt_path.exists():\n",
        "        raise FileNotFoundError(f\"Denoising checkpoint not found at {denoising_ckpt_path}\")\n",
        "\n",
        "    denoising_checkpoint = torch.load(denoising_ckpt_path, map_location=device)\n",
        "    \n",
        "    # 모델 타입 및 설정 할당\n",
        "    global_config.model_type = denoising_checkpoint.get(\"model_type\", \"dncnn\")\n",
        "    global_config.model_config = dncnnconfig\n",
        "    \n",
        "    # 모델 생성 및 state_dict 로드\n",
        "    denoising_network = get_model(global_config).to(device)\n",
        "    denoising_network.load_state_dict(denoising_checkpoint['model_state_dict'])\n",
        "    denoising_network.eval()\n",
        "    \n",
        "    print(f\"Successfully loaded Denoising model ({global_config.model_type}).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the model: {e}\")\n",
        "    denoising_network = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 5. 파이프라인 실행 및 결과 저장\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from code_denoising.datawrapper.datawrapper import DataKey, get_data_wrapper_loader, LoaderConfig\n",
        "\n",
        "if denoising_network:\n",
        "    # --- 기존 결과 폴더 삭제 ---\n",
        "    result_path = Path(RESULT_DIR)\n",
        "    if result_path.exists():\n",
        "        print(f\"Removing old '{RESULT_DIR}' directory...\")\n",
        "        shutil.rmtree(result_path)\n",
        "    result_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # --- 데이터 로더 설정 ---\n",
        "    loader_cfg: LoaderConfig = {\n",
        "        \"data_type\": global_config.data_type,\n",
        "        \"batch\": 8, # GPU 메모리에 맞춰 배치 크기 조절 가능\n",
        "        \"num_workers\": 2,\n",
        "        \"shuffle\": False,\n",
        "        \"augmentation_mode\": 'none',\n",
        "        \"training_phase\": 'end_to_end',\n",
        "        \"noise_type\": global_config.noise_type,\n",
        "        \"noise_levels\": global_config.noise_levels,\n",
        "        \"conv_directions\": global_config.conv_directions\n",
        "    }\n",
        "    data_loader, _ = get_data_wrapper_loader(\n",
        "        file_path=[TEST_DATA_PATH],\n",
        "        training_mode=False,\n",
        "        data_wrapper_class='controlled',\n",
        "        **loader_cfg\n",
        "    )\n",
        "\n",
        "    if not data_loader:\n",
        "        print(f\"Failed to create data loader from {TEST_DATA_PATH}. No data found?\")\n",
        "    else:\n",
        "        print(f\"\\n[Phase 1/1] Creating result files from Denoising + Robust Least Squares pipeline...\")\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(data_loader, desc=\"Processing images\"):\n",
        "                image_noise = data[DataKey.image_noise].to(device)\n",
        "                filenames = data[DataKey.name]\n",
        "\n",
        "                # Step 1: Denoising (학습 모델)\n",
        "                denoised_image_batch = denoising_network(image_noise)\n",
        "\n",
        "                # 💡 수정: 배치 내 각 이미지에 대해 개별적으로 최적 방향 탐색\n",
        "                for i in range(denoised_image_batch.shape[0]):\n",
        "                    single_denoised_tensor = denoised_image_batch[i:i+1]\n",
        "                    \n",
        "                    candidate_results = []\n",
        "                    candidate_variances = []\n",
        "\n",
        "                    # Step 2: 5개 커널 모두에 대해 Deconvolution 수행\n",
        "                    for kernel_k in dipole_kernels_k:\n",
        "                        deconv_result = least_squares_deconv(single_denoised_tensor, kernel_k, LAMBDA)\n",
        "                        candidate_results.append(deconv_result)\n",
        "                        candidate_variances.append(torch.var(deconv_result).item())\n",
        "                    \n",
        "                    # Step 3: 분산이 가장 높은 결과를 최적해로 선택\n",
        "                    best_result_index = np.argmax(candidate_variances)\n",
        "                    final_image_tensor = candidate_results[best_result_index]\n",
        "\n",
        "                    # 결과 저장\n",
        "                    pred_np = final_image_tensor.squeeze().cpu().numpy()\n",
        "                    base_filename = Path(filenames[i]).stem\n",
        "                    np.save(result_path / f\"{base_filename}.npy\", pred_np)\n",
        "        \n",
        "        print(f\"\\nFinished! Results are saved in '{RESULT_DIR}'.\")\n",
        "        print(\"You can now run the 'evaluate.ipynb' notebook to calculate the scores.\")\n",
        "else:\n",
        "    print(\"\\nSkipping pipeline execution because the model failed to load.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
