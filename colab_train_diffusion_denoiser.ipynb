{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diffusion Denoising 모델 학습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정 및 라이브러리 설치\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "%pip install diffusers accelerate transformers loguru --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 프로젝트 경로 설정 및 라이브러리 경로 추가\n",
        "import sys\n",
        "import os\n",
        "\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Data Scientist/Project/Week5/week5'\n",
        "sys.path.append(PROJECT_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 학습 설정 (Configuration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 기존 프로젝트 설정 가져오기\n",
        "from params import config as global_config\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    image_size = global_config.image_size[0]  # 이미지 크기 (정사각형 가정)\n",
        "    train_batch_size = 16\n",
        "    eval_batch_size = 16\n",
        "    num_epochs = 50\n",
        "    gradient_accumulation_steps = 1\n",
        "    learning_rate = 1e-4\n",
        "    lr_warmup_steps = 500\n",
        "    save_image_epochs = 10\n",
        "    save_model_epochs = 10\n",
        "    mixed_precision = 'fp16'  # 'no', 'fp16', 'bf16'\n",
        "    output_dir = os.path.join(PROJECT_PATH, 'logs_diffusion_denoiser')  # 모델 저장 경로\n",
        "\n",
        "    # 데이터로더 설정\n",
        "    train_data_dir = global_config.train_dataset[0]\n",
        "    data_type = global_config.data_type\n",
        "    noise_type = global_config.noise_type\n",
        "    noise_levels = global_config.noise_levels\n",
        "\n",
        "config = TrainingConfig()\n",
        "\n",
        "# 출력 디렉토리 생성\n",
        "if not os.path.exists(config.output_dir):\n",
        "    os.makedirs(config.output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 데이터 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from code_denoising.datawrapper.datawrapper import ControlledDataWrapper, DataKey\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ControlledDataWrapper를 사용하여 학습 데이터셋 로드\n",
        "# augmentation_mode를 'noise_only'로 설정하여 노이즈만 적용된 이미지와 원본 이미지를 받습니다.\n",
        "dataset = ControlledDataWrapper(\n",
        "    file_path=[config.train_data_dir],\n",
        "    data_type=config.data_type,\n",
        "    training_mode='denoising',  # 'denoising' 또는 'deconvolution' 등, 여기서는 노이즈 제거가 목표\n",
        "    augmentation_mode='noise_only',\n",
        "    noise_type=config.noise_type,\n",
        "    noise_levels=config.noise_levels,\n",
        "    conv_directions=[] # 노이즈만 학습하므로 conv는 비워둡니다.\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Successfully loaded {len(dataset)} training images.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Diffusion 모델 및 스케줄러 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "\n",
        "# U-Net 모델 정의\n",
        "# 우리 데이터는 1채널(grayscale) 이미지이므로 in_channels=1, out_channels=1로 설정합니다.\n",
        "model = UNet2DModel(\n",
        "    sample_size=config.image_size,\n",
        "    in_channels=1,  # 흑백 이미지\n",
        "    out_channels=1, # 노이즈 예측 결과도 흑백\n",
        "    layers_per_block=2,\n",
        "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",\n",
        "        \"DownBlock2D\",\n",
        "        \"DownBlock2D\",\n",
        "        \"DownBlock2D\",\n",
        "        \"AttnDownBlock2D\",\n",
        "        \"DownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"UpBlock2D\",\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"UpBlock2D\",\n",
        "        \"UpBlock2D\",\n",
        "        \"UpBlock2D\",\n",
        "        \"UpBlock2D\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 노이즈 스케줄러 정의\n",
        "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "\n",
        "# 옵티마이저 정의\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 학습 루프 (Training Loop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
        "from accelerate import Accelerator\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# 학습률 스케줄러\n",
        "lr_scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=config.lr_warmup_steps,\n",
        "    num_training_steps=(len(train_dataloader) * config.num_epochs),\n",
        ")\n",
        "\n",
        "# Accelerator 초기화\n",
        "accelerator = Accelerator(\n",
        "    mixed_precision=config.mixed_precision,\n",
        "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
        "    log_with=\"tensorboard\",\n",
        "    project_dir=os.path.join(config.output_dir, \"runs\")\n",
        ")\n",
        "\n",
        "if accelerator.is_main_process:\n",
        "    accelerator.init_trackers(\"train_diffusion_denoiser\")\n",
        "\n",
        "# 모델, 옵티마이저, 데이터로더 준비\n",
        "model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, lr_scheduler\n",
        ")\n",
        "\n",
        "global_step = 0\n",
        "# 학습 시작\n",
        "for epoch in range(config.num_epochs):\n",
        "    progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
        "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        clean_images = batch[DataKey.image_gt] # 1채널 원본 이미지\n",
        "        \n",
        "        # 1. 순수 노이즈 생성\n",
        "        noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
        "        bs = clean_images.shape[0]\n",
        "\n",
        "        # 2. 무작위 시간 단계(timestep) 샘플링\n",
        "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,), device=clean_images.device).long()\n",
        "\n",
        "        # 3. 노이즈 추가\n",
        "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
        "\n",
        "        with accelerator.accumulate(model):\n",
        "            # 4. 모델의 노이즈 예측\n",
        "            noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
        "\n",
        "            # 5. Loss 계산 (예측된 노이즈와 실제 노이즈 비교)\n",
        "            loss = F.mse_loss(noise_pred, noise)\n",
        "            accelerator.backward(loss)\n",
        "\n",
        "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        progress_bar.update(1)\n",
        "        logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
        "        progress_bar.set_postfix(**logs)\n",
        "        accelerator.log(logs, step=global_step)\n",
        "        global_step += 1\n",
        "\n",
        "    # 에폭마다 모델 저장\n",
        "    if (epoch + 1) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:\n",
        "        if accelerator.is_main_process:\n",
        "            unwrapped_model = accelerator.unwrap_model(model)\n",
        "            unwrapped_model.save_pretrained(os.path.join(config.output_dir, f\"checkpoint_epoch_{epoch}\"))\n",
        "            print(f\"Saved model checkpoint at epoch {epoch}\")\n",
        "\n",
        "print(\"Training finished.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
