"""
ìµœì¢… í‰ê°€ë¥¼ ìœ„í•œ ê²°ê³¼ë¬¼(.npy íŒŒì¼) ìƒì„± ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•™ìŠµëœ DnCNN ëª¨ë¸(.ckpt)ì„ ë¶ˆëŸ¬ì™€ `test_y` ë°ì´í„°ì…‹ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë³µì›í•˜ê³ ,
`evaluate.ipynb`ê°€ ìš”êµ¬í•˜ëŠ” í˜•ì‹ì— ë§ì¶° ì§€ì •ëœ í´ë”ì— .npy íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path
import warnings
import argparse
import os

import numpy as np
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm

# --- ì¤‘ìš”: ëª¨ë“  import ì´ì „ì— í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€ ---
sys.path.append(str(Path(__file__).resolve().parents[1]))

from code_denoising.common.logger import logger
from code_denoising.core_funcs import get_model, ModelType
from code_denoising.datawrapper.datawrapper import BaseDataWrapper, DataKey, get_data_wrapper_loader
from code_denoising.common.utils import save_numpy_as_image
from params import LoaderConfig, config, parse_args_for_eval_script, unetconfig, dncnnconfig

warnings.filterwarnings("ignore")


def main():
    """
    Main function to run the evaluation.
    """
    # 1. Parse arguments and update the global config
    parse_args_for_eval_script()

    # 2. Setup paths and device
    checkpoint_path = Path(config.checkpoint_path)
    result_dir = Path(config.result_dir)
    result_dir.mkdir(parents=True, exist_ok=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 3. Load model from checkpoint
    logger.info(f"Loading checkpoint from: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # --- ğŸ’¡ ìˆ˜ì •ëœ ëª¨ë¸ íƒ€ì… ê²°ì • ë¡œì§ ---
    # sys.argvë¥¼ ì§ì ‘ í™•ì¸í•˜ì—¬ ì‚¬ìš©ìê°€ ëª…ë ¹ì¤„ì—ì„œ ëª…ì‹œí–ˆëŠ”ì§€ ì²´í¬
    user_overrode_model_type = any(arg.startswith('--model_type') for arg in sys.argv)

    if user_overrode_model_type:
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í–ˆë‹¤ë©´, parse_args_for_eval_scriptê°€ ì´ë¯¸ configì— ì„¤ì •í–ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        logger.info(f"User explicitly specified model type: {config.model_type}")
    else:
        # ì‚¬ìš©ìê°€ ì§€ì •í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜´
        logger.info("Inferring model type from checkpoint...")
        model_type_from_ckpt = checkpoint.get('model_type')
        if model_type_from_ckpt:
            config.model_type = model_type_from_ckpt
        else:
            # ì²´í¬í¬ì¸íŠ¸ì—ë„ ì •ë³´ê°€ ì—†ìœ¼ë©´, ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ ê¸°ë³¸ê°’ì„ ì‚¬ìš© (ì´ ê²½ìš° configì˜ ê¸°ë³¸ê°’)
            logger.warning(f"Model type not found in checkpoint. Falling back to default: {config.model_type}")

    logger.info(f"Using model type: {config.model_type}")
    
    # ì›ìƒ ë³µêµ¬: Trainer.__init__ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ model_configë¥¼ ë™ì ìœ¼ë¡œ ì¶”ê°€
    if ModelType.from_string(config.model_type) == ModelType.Unet:
        config.model_config = unetconfig
    elif ModelType.from_string(config.model_type) == ModelType.DnCNN:
        config.model_config = dncnnconfig

    # Deconvolution ëª¨ë“œì¼ ë•Œë§Œ ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ 2ë¡œ ë³€ê²½ (íš¨ê³¼ê°€ ìˆì—ˆë˜ ìµœì†Œ ìˆ˜ì •)
    if config.augmentation_mode in ['conv_only', 'both']:
        config.model_config.in_chans = 2
        logger.info("Setting model input channels to 2 for deconvolution.")

    model = get_model(config).to(device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # 4. Setup data loader for the test dataset
    loader_cfg = {
        "data_type": '*.npy',
        "batch": 1,  # Process one image at a time
        "num_workers": 0,
        "shuffle": False,
        "augmentation_mode": 'none', # No augmentation during evaluation
        "training_phase": 'end_to_end', # This doesn't matter for eval but needs a value
        "noise_type": "gaussian",
        "noise_levels": [],
        "conv_directions": []
    }
    test_loader, _ = get_data_wrapper_loader(
        file_path=config.test_dataset,
        training_mode=False,
        data_wrapper_class='controlled',
        **loader_cfg
    )

    # 5. Run inference and save results
    logger.info(f"Starting inference on {len(test_loader.dataset)} images...")
    with torch.no_grad():
        for data in tqdm(test_loader):
            input_tensor = data[DataKey.image_noise].to(device)
            # íŒŒì¼ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ì˜¤ëŠ” ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì‚¬ìš©
            filename = data[DataKey.name][0] if isinstance(data[DataKey.name], list) else data[DataKey.name]

            output_tensor = model(input_tensor)

            output_np = output_tensor.squeeze().cpu().numpy()
            save_path = result_dir / f"{Path(filename).stem}.npy"
            np.save(save_path, output_np)
    
    logger.info(f"Inference complete. Results saved to: {result_dir}")

if __name__ == "__main__":
    main()
