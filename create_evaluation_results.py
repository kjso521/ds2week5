"""
ìµœì¢… í‰ê°€ë¥¼ ìœ„í•œ ê²°ê³¼ë¬¼(.npy íŒŒì¼) ìƒì„± ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•™ìŠµëœ DnCNN ëª¨ë¸(.ckpt)ì„ ë¶ˆëŸ¬ì™€ `test_y` ë°ì´í„°ì…‹ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë³µì›í•˜ê³ ,
`evaluate.ipynb`ê°€ ìš”êµ¬í•˜ëŠ” í˜•ì‹ì— ë§ì¶° ì§€ì •ëœ í´ë”ì— .npy íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import argparse
import os
from pathlib import Path
import sys
import warnings

# --- ì¤‘ìš”: ëª¨ë“  import ì´ì „ì— í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€ ---
# ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, ìƒìœ„ 1ë‹¨ê³„ í´ë”(week5)ë¥¼ ê²½ë¡œì— ì¶”ê°€í•©ë‹ˆë‹¤.
sys.path.append(str(Path(__file__).resolve().parents[1]))

import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„ìš”í•œ ëª¨ë“ˆ import
from code_denoising.datawrapper.datawrapper import DataKey, get_data_wrapper_loader, LoaderConfig
from code_denoising.core_funcs import get_model
from params import config, parse_args_for_eval_script  # Import the new parsing function
from code_denoising.common.logger import logger

warnings.filterwarnings("ignore")

def create_results(
    network: torch.nn.Module,
    data_loader: DataLoader,
    result_dir: str,
):
    """
    Generate and save model outputs.
    """
    result_path = Path(result_dir)
    result_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"Saving results to {result_path}")

    total_psnr = 0.0
    total_ssim = 0.0
    count = 0

    with torch.no_grad():
        for data in tqdm(data_loader, leave=False):
            image_noise = data[DataKey.image_noise].to(config.device)
            filenames = data[DataKey.name]

            image_pred = network(image_noise)

            for i in range(image_pred.shape[0]):
                pred_np = image_pred[i, 0, :, :].cpu().numpy()
                filename = filenames[i]
                
                # Ensure the saved file has the original extension stripped
                base_filename = Path(filename).stem
                
                np.save(result_path / f"{base_filename}.npy", pred_np)
    
    logger.info("Finished creating result files.")


def main():
    """
    Main function to run the evaluation.
    """
    # 1. Parse arguments and update the global config
    parse_args_for_eval_script()

    # 2. Setup paths and device
    checkpoint_path = Path(config.checkpoint_path)
    result_dir = Path(config.result_dir)
    result_dir.mkdir(parents=True, exist_ok=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 3. Load model from checkpoint
    logger.info(f"Loading checkpoint from: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # --- ğŸ’¡ ìˆ˜ì •ëœ ëª¨ë¸ íƒ€ì… ê²°ì • ë¡œì§ ---
    # ì‚¬ìš©ìê°€ --model_type ì¸ìë¥¼ ì§ì ‘ ì¤¬ëŠ”ì§€ í™•ì¸
    user_overrode_model_type = '--model_type' in sys.argv

    if user_overrode_model_type:
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í–ˆë‹¤ë©´, parse_args_for_eval_scriptê°€ ì´ë¯¸ configì— ì„¤ì •í–ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        logger.info(f"User explicitly specified model type: {config.model_type}")
    else:
        # ì‚¬ìš©ìê°€ ì§€ì •í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜´
        logger.info("Inferring model type from checkpoint...")
        model_type_from_ckpt = checkpoint.get('model_type')
        if model_type_from_ckpt:
            config.model_type = model_type_from_ckpt
        else:
            # ì²´í¬í¬ì¸íŠ¸ì—ë„ ì •ë³´ê°€ ì—†ìœ¼ë©´, ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ ê¸°ë³¸ê°’ì„ ì‚¬ìš©
            logger.warning(f"Model type not found in checkpoint. Falling back to default: {config.model_type}")

    logger.info(f"Using model type: {config.model_type}")
    model = get_model(config).to(device)
    state_dict = checkpoint.get('model_state_dict')
    if not state_dict:
        raise ValueError("Could not find a valid 'model_state_dict' in the checkpoint.")
    model.load_state_dict(state_dict)
    model.eval()

    # 4. Setup data loader for the test dataset
    loader_cfg = LoaderConfig(
        data_type='*.npy',
        batch=1,  # Process one image at a time
        num_workers=0,
        shuffle=False,
        augmentation_mode='none', # No augmentation during evaluation
        training_phase='end_to_end', # This doesn't matter for eval but needs a value
        noise_type="gaussian",
        noise_levels=[],
        conv_directions=[]
    )
    test_loader, _ = get_data_wrapper_loader(
        file_path=config.test_dataset,
        loader_cfg=loader_cfg,
        training_mode=False,
        data_wrapper_class='controlled' # Use the flexible datawrapper
    )

    # 5. Run inference and save results
    logger.info(f"Starting inference on {len(test_loader.dataset)} images...")
    with torch.no_grad():
        for data in tqdm(test_loader):
            input_tensor = data[DataKey.image_noise].to(device)
            filename = data[DataKey.filename]

            output_tensor = model(input_tensor)

            output_np = output_tensor.squeeze().cpu().numpy()
            save_path = result_dir / f"{Path(filename).stem}.npy"
            np.save(save_path, output_np)
    
    logger.info(f"Inference complete. Results saved to: {result_dir}")

if __name__ == "__main__":
    main()
