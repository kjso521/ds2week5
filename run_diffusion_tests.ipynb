{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Restoration Pipeline Test\n",
        "\n",
        "This notebook tests the full advanced restoration pipeline in a logical sequence:\n",
        "1. **Find the Correct Deconvolution Direction:** Use `ClippedInverseFilter` to test all 5 possible directions and visually identify the most likely \"correct\" one for the sample image.\n",
        "2. **Run PnP Restoration:** Use the \"correct\" direction found in step 1 as input for the `PnP_Restoration` algorithm to see its true performance.\n",
        "3. **(Optional) Run DiffPIR:** As a comparison, run the `DiffPIR_Pipeline` using the same \"correct\" direction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# --- Environment Setup ---\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running in Google Colab. Mounting Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    ROOT = Path('/content/drive/MyDrive/Data Scientist/Project/Week5/week5') \n",
        "    %cd {ROOT}\n",
        "    !git pull origin main\n",
        "else:\n",
        "    print(\"Running in local environment.\")\n",
        "    ROOT = Path.cwd()\n",
        "\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.append(str(ROOT))\n",
        "print(f\"Project Root set to: {ROOT}\")\n",
        "\n",
        "# --- Module Imports ---\n",
        "from code_denoising.classical_methods.deconvolution import ClippedInverseFilter\n",
        "from code_denoising.diffusion_methods.hf_denoiser import HuggingFace_Denoiser\n",
        "from code_denoising.diffusion_methods.hf_diffpir import DiffPIR_Pipeline\n",
        "from code_denoising.pnp_restoration import PnP_Restoration\n",
        "from diffusers import DDPMScheduler, UNet2DModel\n",
        "\n",
        "print(\"Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 1. Load Sample Data & Define Constants ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the sample degraded image\n",
        "try:\n",
        "    sample_path = ROOT / \"dataset/test_y/L1_000d090392623f8046ebe84a1b345bf7.npy\"\n",
        "    sample_image_np = np.load(sample_path)\n",
        "except FileNotFoundError:\n",
        "    # Adjust path for Colab if the dataset is a sibling folder\n",
        "    sample_path = ROOT.parent / \"dataset/test_y/L1_000d090392623f8046ebe84a1b345bf7.npy\"\n",
        "    sample_image_np = np.load(sample_path)\n",
        "    \n",
        "sample_image_torch = torch.from_numpy(sample_image_np).unsqueeze(0).unsqueeze(0).float().to(DEVICE)\n",
        "\n",
        "# Define the 5 known convolution directions\n",
        "B0_DIRS = [(-0.809, -0.5878), (-0.809, 0.5878), (0.309, -0.9511), (0.309, 0.9511), (1.0, 0.0)]\n",
        "\n",
        "def plot_image(tensor, title=\"\"):\n",
        "    plt.imshow(tensor.squeeze().cpu().numpy(), cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.figure()\n",
        "plot_image(sample_image_torch, title=\"Original Degraded Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Find the Correct Deconvolution Direction\n",
        "We run `ClippedInverseFilter` for all 5 directions. The output that looks the most structured and least like noise/artifacts is the result of applying the \"correct\" deconvolution kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deconv_filter = ClippedInverseFilter()\n",
        "restored_images_deconv = deconv_filter.run_on_all_directions(sample_image_torch, B0_DIRS)\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.subplot(1, 6, 1)\n",
        "plot_image(sample_image_torch, title=\"Input\")\n",
        "for i, (img, b0_dir) in enumerate(zip(restored_images_deconv, B0_DIRS)):\n",
        "    plt.subplot(1, 6, i + 2)\n",
        "    plot_image(img, title=f\"Deconv Dir {i+1}\")\n",
        "plt.suptitle(\"ClippedInverseFilter Results for all 5 Directions\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Based on visual inspection, we determine the most likely correct direction index.\n",
        "# From the previous run, Dir 2 (-0.809, 0.5878) looked the most promising.\n",
        "CORRECT_DIR_INDEX = 1 # Index 1 corresponds to Dir 2\n",
        "correct_b0_dir = B0_DIRS[CORRECT_DIR_INDEX]\n",
        "print(f\"Visually identified correct direction: Dir {CORRECT_DIR_INDEX+1} -> {correct_b0_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Run PnP Restoration with the Correct Direction\n",
        "Now we use the `correct_b0_dir` identified above to run the PnP algorithm. This should yield a much better result than before.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the pre-trained denoiser model\n",
        "model_save_path = ROOT / \"hf_models/ddpm-celebahq-256\"\n",
        "if not model_save_path.exists():\n",
        "    # This will trigger download and save on first run\n",
        "    print(\"Downloading and saving denoiser model for the first time...\")\n",
        "    denoiser_for_save = HuggingFace_Denoiser(model_name=\"google/ddpm-celebahq-256\", device=DEVICE)\n",
        "    denoiser_for_save.model.save_pretrained(model_save_path)\n",
        "    denoiser_for_save.scheduler.save_pretrained(model_save_path)\n",
        "    print(\"Model saved.\")\n",
        "else:\n",
        "    print(\"Loading denoiser model from local path.\")\n",
        "\n",
        "denoiser = HuggingFace_Denoiser(model_name=str(model_save_path), device=DEVICE)\n",
        "pnp_restorer = PnP_Restoration(denoiser=denoiser)\n",
        "\n",
        "print(f\"Running PnP Restoration with direction: {correct_b0_dir}\")\n",
        "restored_image_pnp = pnp_restorer.run(\n",
        "    degraded_image=sample_image_torch,\n",
        "    B0_dir=correct_b0_dir,\n",
        "    max_iter=10,\n",
        "    rho=1.0, # This is a key hyperparameter to tune\n",
        "    denoiser_noise_level=50 # This is another key hyperparameter\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_image(sample_image_torch, title=\"Input\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_image(restored_image_pnp, title=\"PnP Restored Output (Corrected)\")\n",
        "plt.suptitle(\"PnP_Restoration Result\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Hyperparameter Tuning for PnP\n",
        "The result from Step 2 was poor, which is expected with default hyperparameters. Now, we'll test a range of `rho` and `denoiser_noise_level` values to find a better combination for our specific image.\n",
        "\n",
        "- `rho`: Balances deconvolution and denoising.\n",
        "- `denoiser_noise_level`: Tells the denoiser how aggressively to remove noise. Our original noise sigmas were ~0.07-0.13, which are ~18-33 on a 0-255 scale. We should test values in this range.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# Define ranges for hyperparameters\n",
        "rho_values = [0.1, 1.0, 5.0]\n",
        "noise_level_values = [15, 25, 35]\n",
        "\n",
        "# Store results\n",
        "pnp_tuning_results = []\n",
        "\n",
        "# Create all combinations\n",
        "param_combinations = list(itertools.product(rho_values, noise_level_values))\n",
        "\n",
        "print(f\"Testing {len(param_combinations)} hyperparameter combinations...\")\n",
        "\n",
        "for rho_val, noise_level_val in param_combinations:\n",
        "    print(f\"  Testing rho = {rho_val}, noise_level = {noise_level_val}...\")\n",
        "    restored_image = pnp_restorer.run(\n",
        "        degraded_image=sample_image_torch,\n",
        "        B0_dir=correct_b0_dir,\n",
        "        max_iter=10,\n",
        "        rho=rho_val,\n",
        "        denoiser_noise_level=noise_level_val\n",
        "    )\n",
        "    pnp_tuning_results.append({\n",
        "        'rho': rho_val,\n",
        "        'noise_level': noise_level_val,\n",
        "        'image': restored_image\n",
        "    })\n",
        "\n",
        "print(\"Tuning finished.\")\n",
        "\n",
        "# Plot the results\n",
        "num_results = len(pnp_tuning_results)\n",
        "num_cols = len(noise_level_values)\n",
        "num_rows = len(rho_values)\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 4, num_rows * 4))\n",
        "fig.suptitle('PnP Hyperparameter Tuning Results', fontsize=20)\n",
        "\n",
        "for i, result in enumerate(pnp_tuning_results):\n",
        "    row = i // num_cols\n",
        "    col = i % num_cols\n",
        "    ax = axes[row, col]\n",
        "    ax.imshow(result['image'].squeeze().cpu().numpy(), cmap='gray')\n",
        "    ax.set_title(f\"rho={result['rho']}, noise={result['noise_level']}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
